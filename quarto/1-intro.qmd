---
title: Introduction
format: 
    html:
        mermaid:
            theme: neutral
---

## Welcome

Welcome. If we must guess, you're an engineer who would like to understand statistics, but long discussions on hypothesis testing or derivations of parametric probability distributions don't seem to be helping you figure it out. We feel you. And you're probably in a hurry. We feel that too.

## The Premise

The premise of this primer is that we can introduce statistics as a loop involving just two processes:

1.  Estimating the probability of data, or making predictions, given a model of a data generating process.
2.  Maximizing the likelihood (accuracy) of a model, given observed data.

We will refer to the real-world process of interest as the **data generating process**, and we will attempt to summarize it mathematically with a **model**. When we work in the 'forward' direction, where the model is assumed constant, we will find the **probability** of the data. (The probability of existing data and predicting new data are two sides of the same coin). When we work in the 'reverse' direction, where we are trying to find the best model given the observed data, we maximize the **likelihood** of the model.

The chart below is a simple visual summary. The equations can be read as 'probability of the data given the model' and 'likelihood of the model given the data'.

```{mermaid}
flowchart LR
    A(["P(D|M)"]) --> B(["â„’(M|D)"])
    B --> A
```

::: callout-note
Hopefully we haven't lost you already. $\mathcal{L}(M \mid D)$ is about creating accurate models, which any engineer can appreciate. We don't start there, however, because it's a little like building a car before you know how to drive. Instead we start by giving you models that can generate data. Models that generate data can either help you predict future data or show you how likely you were to get the data you already have, i.e. $P(D \mid M)$.
:::

## Models and Uncertainty

In engineering, a model tends to spark thoughts of systems of interrelated equations that spit out a single answer. But it's silly to think that answer is precise to all those digits. The real world has plenty of uncertainty, and that's probably why you've been sucked into the statistical void. In this new world we need to acknowledge two kinds of uncertainty:

-   Aleatoric Uncertainty (Randomness)
-   Epistemic Uncertainty (Lack of Knowledge)

Statistics is fine with both. In fact it will usually bundle up both of them without a second thought and simply try to estimate the outcome without becoming too concerned with the underlying process. This is a fine place to start, but eventually we will work our way back to a place where we can incorporate those underlying processes into our new statistical frameworks.