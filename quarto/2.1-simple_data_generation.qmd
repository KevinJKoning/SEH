---
title: Discrete Probability Distributions
format: html
filters:
  - shinylive
---

## Preview

In the first half of the primer we focus on $P(D|M)$, the probability of the [data]{style="text-decoration: underline;"} given a [model]{style="text-decoration: underline;"} of a data generating process. This first chapter considers only models with discrete (in contrast with continuous) outputs. We use dice as our first example as it is hopefully an intuitive subject. We then introduce more *discrete probability distributions* as models of other idealized processes. For the first half of the primer we will not question our models, we will consider them as set/frozen and just allow them to generate data for us, assuming that they represent the data generating process of interest.

Once we have have some discussion of models under our belt, we will change our focus to the probability of data. For any model we can use the relative frequency of an event to approximate the events probability. We will show how the accuracy of this probability estimate increases with the number of samples. Where an analytical solution of $P(D|M)$ is available, we will also compare exact probabilities to those estimated from relative frequency.

We then shift to the probability of multiple events based on the laws of probability for independent events. We show how we can use computation to calculate the relative probability of a specific series of events by comparing it to a multitude of randomly generated series of events. We use the example of finding the probability that a die is weighted (unfair) after an observed series of rolls. This is our more intuitive approach to hypothesis testing.

## Models of Data Generating Processes

### A Dice Total Model

We'd prefer not to spend too much time on toy examples, however, there are a lot of benefits to starting with something that is intuitive and simple. Subsequently we'll use rolling dice as our first example of a data generating process. It is also convenient that the mathematical model we'll use is an awfully good approximation of the real data generating process, so long as you're OK with ignoring all the physical bouncing of the dice and are content with just the result after a roll.

A dice model is built into the app displayed beneath this paragraph. It will simulate rolling the number of dice you specify, as if you threw them out of a cup all at once, and total the value on those dice from the cup, which is considered one roll. Additionally, it will repeat rolling that cup of dice the number of times you specify, and summarize the results on a histogram. Play around with the two inputs/parameters of the dice rolling app below, the number of dice and the number of rolls.

```{shinylive-python}
#| standalone: true
#| viewerHeight: 550

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt

app_ui = ui.page_fluid(
    ui.h2("Dice Rolling App"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_slider("numDice", "Number of Dice", min=1, max=10, value=2, step=1),
            ui.input_slider("numRolls", "Number of Rolls", min=1, max=10000, value=100, step=1),
        ),
        ui.output_plot("dicePlot", height="400px"),
    ),
)

def server(input, output, session):
    # Define a reactive calculation that depends on numDice and numRolls
    @reactive.Calc
    def dice_sums():
        return [
            np.random.randint(1, 7, input.numDice()).sum()
            for _ in range(input.numRolls())
        ]

    @output
    @render.plot
    def dicePlot():
        current_sums = dice_sums()
        fig, ax = plt.subplots()

        unique_sums, counts = np.unique(current_sums, return_counts=True)
        ax.bar([str(s) for s in unique_sums], counts, color="steelblue")

        ax.set_title("Frequency of Dice Totals")
        ax.set_xlabel("Dice Total")
        ax.set_ylabel("Frequency")
        plt.xticks(rotation=90)

        return fig

app = App(app_ui, server)
```

Hopefully you've noted how a larger number of rolls seems to give us smoother and more consistent results. We will revisit this point more precisely in a later section.

### Discrete Probability Distributions as Models of Data Generating Processes

In the last section, we used dice rolling as our data generating process, however there are other discrete processes we may be interested in, such as testing 1,000 products that have a 0.995 probability of success each. As you can imagine, when you change the data generating process, the relative frequency of the possible events/outcomes changes. There are a number of discrete processes that have been interesting to statisticians, and they have been formalized into mathematical models called *discrete probability distributions*.

::: callout-note
If you are familiar with discrete probability distributions, you may have expected them to be introduced as a way to find the exact probability of an event, instead of using them to generate data. We will eventually use this 'feature', but our goal is to more generally introduce models of data generating processes and their associated probability distributions. Only a small number have properties that allow for nice analytical solutions to the probabilities of their data, and we'd prefer not to constrain ourselves to thinking in only an analytical (as opposed to computational) framework.
:::

Initially we want to think about discrete probability distributions in the same way we thought about our dice model, that it is a model that will generate random events from a data generating process of interest. Below are a couple examples to illustrate the point.

#### Binomial Distribution

The binomial distribution is a model that represents the number of successes in a fixed number of independent trials, where each trial has two possible outcomes (commonly referred to as “success” and “failure”). The probability of success can range between 0 and 1. In the app below you can recreate something like the product testing scenario recently mentioned. Feel free to play around with the settings/parameters to get a feel for how the probability distribution behaves.


```{shinylive-python}
#| standalone: true
#| viewerHeight: 550

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt
import math

app_ui = ui.page_fluid(
    ui.h2("Binomial Distribution Simulation with Binned Histogram"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_slider(
                "numTrials", 
                "Number of Trials (n)", 
                min=1, 
                max=10000, 
                value=100, 
                step=1
            ),
            ui.input_slider(
                "probSuccess", 
                "Probability of Success (p)", 
                min=0.001, 
                max=0.999, 
                value=0.5, 
                step=0.001
            ),
            # Removed the "Number of Simulations" slider
            # Fixed number of simulations to 10,000
        ),
        ui.output_plot("binomPlot", height="400px"),
    ),
)

def server(input, output, session):
    # Fixed number of simulations
    FIXED_NUM_SIMULATIONS = 10000

    # Reactive expression to generate binomial samples
    @reactive.Calc
    def binomial_samples():
        n = input.numTrials()
        p = input.probSuccess()
        size = FIXED_NUM_SIMULATIONS
        return np.random.binomial(n, p, size)
    
    # Function to determine optimal integer bin width
    def determine_bin_width(data, max_bins=30):
        data_min = data.min()
        data_max = data.max()
        data_range = data_max - data_min + 1  # +1 to include both endpoints
        # Start with bin_width = 1 and increase until the number of bins <= max_bins
        for bin_width in range(1, data_range + 1):
            num_bins = math.ceil(data_range / bin_width)
            if num_bins <= max_bins:
                return bin_width
        return 1  # Fallback to bin_width=1 if all else fails
    
    # Render the binomial distribution plot with limited bins
    @output
    @render.plot
    def binomPlot():
        samples = binomial_samples()
        bin_width = determine_bin_width(samples, max_bins=30)
        
        # Define bin edges based on bin_width
        data_min = samples.min()
        data_max = samples.max()
        bins = np.arange(data_min, data_max + bin_width, bin_width)
        
        # Compute histogram
        counts, bin_edges = np.histogram(samples, bins=bins)
        bin_centers = bin_edges[:-1] + bin_width / 2
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        ax.bar(bin_centers, counts, width=bin_width*0.9, color="steelblue", edgecolor="black", align='center')
        
        ax.set_title("Frequency of Successes in Binomial Simulations", fontsize=16)
        ax.set_xlabel("Number of Successes", fontsize=14)
        ax.set_ylabel("Frequency", fontsize=14)
        #ax.grid(True, axis='y', linestyle='--', alpha=0.7)
        
        # Set x-axis ticks to be at bin centers
        ax.set_xticks(bin_centers)
        
        # To avoid overcrowding, set a maximum number of x-ticks
        if len(bin_centers) > 20:
            step = math.ceil(len(bin_centers) / 20)
            ax.set_xticks(bin_centers[::step])
            ax.set_xticklabels([int(x) for x in bin_centers[::step]], rotation=90)
        else:
            ax.set_xticklabels([int(x) for x in bin_centers], rotation=90)
        
        plt.tight_layout()
        
        return fig

app = App(app_ui, server)
```



#### Poisson Distribution

The Poisson distribution is a model that describes the number of events occurring in a fixed interval of time or space, assuming that the events occur independently and at a constant average rate. For example, it might represent the number of phone calls received by a call center in an hour or the number of cars passing through a toll booth in a minute. The Poisson Distribution is similar to the Binomial distribution, except there are not a fixed number of trials, so there is not an upper limit to the number of events returned by a sample. However, values much larger than the average rate become incredibly unlikely.


```{shinylive-python}
#| standalone: true
#| viewerHeight: 550

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import poisson
import math

# Define the User Interface
app_ui = ui.page_fluid(
    ui.h2("Poisson Distribution Simulation"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_slider(
                "rate_param", 
                "Rate Parameter (λ)", 
                min=0.01, 
                max=10.0, 
                value=1.0, 
                step=0.01
            ),
            ui.input_slider(
                "num_trials",
                "Times to Repeat Sample",
                min=100,
                max=10000,
                value=10000,
                step=100
            )
        ),
        ui.output_plot("poissonPlot", height="400px"),
    )
)

# Define the Server Logic
def server(input, output, session):

    # Reactive expression to get the number of simulations
    @reactive.Calc
    def num_simulations():
        return input.num_trials()

    # Reactive expression to generate Poisson samples
    @reactive.Calc
    def poisson_samples():
        lam = input.rate_param()
        n_trials = num_simulations()
        return np.random.poisson(lam, n_trials)
    
    # Function to determine optimal integer bin width with a maximum number of bins
    def determine_bin_width(data, max_bins=30):
        data_min = data.min()
        data_max = data.max()
        data_range = data_max - data_min + 1  # +1 to include both endpoints
        # Start with bin_width = 1 and increase until the number of bins <= max_bins
        for bin_width in range(1, data_range + 1):
            num_bins = math.ceil(data_range / bin_width)
            if num_bins <= max_bins:
                return bin_width
        return 1  # Fallback to bin_width=1 if all else fails

    # Render the Poisson distribution plot
    @output
    @render.plot
    def poissonPlot():
        samples = poisson_samples()
        lam = input.rate_param()
        
        bin_width = determine_bin_width(samples, max_bins=30)
        
        # Define bin edges based on bin_width
        data_min = samples.min()
        data_max = samples.max()
        bins = np.arange(data_min, data_max + bin_width, bin_width)
        
        # Compute histogram
        counts, bin_edges = np.histogram(samples, bins=bins)
        bin_centers = bin_edges[:-1] + bin_width / 2
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Plot the histogram
        ax.bar(bin_centers, counts, width=bin_width*0.9, color="steelblue", edgecolor="black", align='center')
        
        ax.set_title(f"Poisson Distribution Simulation (λ = {lam})", fontsize=16)
        ax.set_xlabel("Number of Events", fontsize=14)
        ax.set_ylabel("Frequency", fontsize=14)
        #ax.grid(True, axis='y', linestyle='--', alpha=0.7)
        
        # Set x-axis ticks to be at bin centers
        ax.set_xticks(bin_centers)
        
        # To avoid overcrowding, set a maximum number of x-ticks
        if len(bin_centers) > 20:
            step = math.ceil(len(bin_centers) / 20)
            ax.set_xticks(bin_centers[::step])
            ax.set_xticklabels([int(x) for x in bin_centers[::step]], rotation=90)
        else:
            ax.set_xticklabels([int(x) for x in bin_centers], rotation=90)
        
        plt.tight_layout()
        
        return fig

# Create the Shiny App
app = App(app_ui, server)
```


#### Summary

We keep this section brief as there are plenty of easily accessible references for discrete probability distributions. Hopefully the point was made though - that each discrete probability distribution is built on an idealized data generating process, and we can sample from the distribution as a way to model the outcome of the process.

## Probability of Data

Having given some background on models, we can now focus on the probability of the data given the model, $P(D|M)$.

### Dice Totals Probability of Data

We want to find the probability of a particular dice total (the data) given a dice model. To estimate the probability $P(E)$ of an event $E$, we can use the relative frequency approach. This involves counting the number of occurrences of the event E and dividing it by the total number of trials. For example, if we observed a total of twelve occur in 40 out of 5,000 dice rolls, the probability estimate is:

$$
P(E) \approx \frac{\text{Number of times event } E \text{ occurs}}{\text{Total number of trials}} = \frac{40}{5000} = 0.008
$$

The accuracy of this estimate depends on the total number of trials as governed by the Law of Large Numbers. The standard error, which gives a measure of uncertainty in the estimate of a mean value, is proportional to one over the square root of the number of samples:

$$
P_{\text{error}} \propto \frac{1}{\sqrt{N_{\text{total}}}}
$$

Which indicates there are diminishing returns to just making the sample size larger. Now I know you're smart, and you're saying to yourself, I can figure out the *exact* probability of rolling a certain dice total. Of course you can for this example - but you probably can't for more realistic examples, and we want to learn techiques that work well for real problems. In general, if you are concerned with the quality of an estimate with this approach, just rerun the model and see if the outcome changes meaningfully - if it does, increase the number of times we run the model until the output is stable enough for your application. If that's still not enough, dig into exact/analytic methods.

Here's another version of the Dice Total App that you saw earlier - except it now has additional functionality to calculate the approximate and exact probability of a certain dice total based on your inputs.

```{shinylive-python}
#| standalone: true
#| viewerHeight: 550

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt

# --- Utility function to compute exact distribution of sums for n dice ---
def dice_sum_distribution(n_dice):
    """
    Return a list 'dist' where dist[s] = probability of sum s for n_dice dice.
    Indices go from 0 up to 6*n_dice. Only sums in range [n_dice..6*n_dice]
    have nonzero probabilities.
    """
    # ways[s] = number of ways to get sum s
    ways = [0] * (6*n_dice + 1)
    ways[0] = 1  # base case

    for _ in range(n_dice):
        new_ways = [0] * (6*n_dice + 1)
        for sum_val, count in enumerate(ways):
            if count > 0:
                for face in range(1, 7):
                    new_ways[sum_val + face] += count
        ways = new_ways

    total_outcomes = 6 ** n_dice
    dist = [count / total_outcomes for count in ways]
    return dist

# -------------------------- UI Definition ---------------------------
app_ui = ui.page_fluid(
    ui.h2("Dice Rolling App with Probability of Data"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_slider("numDice", "Number of Dice", min=1, max=10, value=2, step=1),
            ui.input_slider("numRolls", "Number of Rolls", min=1, max=10000, value=100, step=1),
            ui.input_select(
                "selectedTotal", 
                "Select Dice Total", 
                choices=[""],   # initially empty, will be updated dynamically
                multiple=False,
            ),
            ui.output_text("approxProbability"),
            ui.output_text("exactProbability")
        ),
        ui.output_plot("dicePlot", height="400px"),
    )
)

# -------------------------- Server Definition -------------------------
def server(input, output, session):
    # Reactive: Generate random sums based on numDice and numRolls
    @reactive.Calc
    def dice_sums():
        return [
            np.random.randint(1, 7, input.numDice()).sum()
            for _ in range(input.numRolls())
        ]

    # Reactive: Exact distribution of sums for the current number of dice
    @reactive.Calc
    def exact_distribution():
        return dice_sum_distribution(input.numDice())

    # Dynamically update the choices in the 'selectedTotal' select input
    @reactive.Effect
    def _():
        current_sums = dice_sums()
        unique_sums = sorted(np.unique(current_sums))
        ui.update_select(
            "selectedTotal",
            choices=[str(s) for s in unique_sums],
            selected=str(unique_sums[0]) if len(unique_sums) > 0 else ""
        )

    # Plot the frequency of dice totals
    @output
    @render.plot
    def dicePlot():
        current_sums = dice_sums()

        fig, ax = plt.subplots()
        unique_sums, counts = np.unique(current_sums, return_counts=True)
        ax.bar([str(s) for s in unique_sums], counts, color="steelblue")

        ax.set_title("Frequency of Dice Totals")
        ax.set_xlabel("Dice Total")
        ax.set_ylabel("Frequency")
        plt.xticks(rotation=90)

        return fig

    # Approximate probability of the selected dice total
    @output
    @render.text
    def approxProbability():
        if not input.selectedTotal():
            return "Select a dice total to see probabilities."

        current_sums = dice_sums()
        selected_total = int(input.selectedTotal())

        count = sum(1 for x in current_sums if x == selected_total)
        if len(current_sums) == 0:
            prob = 0
        else:
            prob = count / len(current_sums)

        return f"Approx. Probability of {selected_total}: {prob:.4f}"

    # Exact probability of the selected dice total
    @output
    @render.text
    def exactProbability():
        if not input.selectedTotal():
            return ""

        selected_total = int(input.selectedTotal())
        dist = exact_distribution()

        # If the selected total is out of range, probability is 0
        if selected_total < 0 or selected_total >= len(dist):
            prob = 0
        else:
            prob = dist[selected_total]

        return f"Exact Probability of {selected_total}: {prob:.4f}"

app = App(app_ui, server)
```

Hopefully you can demonstrate to yourself that with enough samples, the approximate probability calculation is awfully close to the exact probability. However, there is an exception. The tails (the slim far ends) are not as accurate. Properly calculating probability in these tail sections happens to be trivial for dice where an exact solution is available, but for a real problem, accurate tail probabilities are incredibly difficult.  

::: callout-note
A few readers may already know an essay called the 'The Bitter Lesson' by Rich Sutton. If you haven't read it, it is worth a read, and easily found on the internet. I believe it has a strong engineering corollary, in that our education is too obsessed with analytical solutions instead of computational ones. To temper that statement slightly, I can also assure you that solving problems through raw computation has its limits as there's no way to compute through a bad algorithm. But we're professionals in a hurry, we choose computation whenever it's plausible.
:::

**delete these???**
### Discrete Probability Distributions Probability of Data
...
#### Relative Frequency Technique
Show we can use relative frequency technique like with the dice.

### Exact Probabilities

Most of the primer is focused on simulation without going into the code itself, however, once you know what you're after it's not that hard to reproduce in whatever computational environment you prefer. Since the exact probabilities of discrete probability distributions can be computed by hand, we'll walk through one of the few opportunities for some straightforward math.

Let's use the properties of the binomial probability distribution to determine the probability of having exactly 995 products pass inspection when we have a 0.995 pass rate and we inspect 1,000 products.

1. **Identify distribution parameters:**
   - \(n = 1000\) (number of products tested)
   - \(k = 995\) (number of products passing)
   - \(p = 0.995\) (probability of a product passing)

2. **Plug into the binomial probability formula:**

$$
P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}
$$

$$
P(X = 995) = \binom{1000}{995} (0.995)^{995} (0.005)^5
$$

3. **Calculate the binomial coefficient:**

$$
\binom{1000}{995} = \frac{1000!}{995! \cdot 5!} = \frac{1000 \cdot 999 \cdot 998 \cdot 997 \cdot 996}{5 \cdot 4 \cdot 3 \cdot 2 \cdot 1} = 8,244,528,275
$$

4. **Compute the probabilities:**

$$
(0.995)^{995} \approx 0.78029, \quad (0.005)^5 = 0.0000003125
$$

5. **Combine terms:**

$$
P(X = 995) = 8,244,528,275 \cdot 0.78029 \cdot 0.0000003125
$$

$$
P(X = 995) \approx 0.1759
$$

**Final Answer:** The probability of passing exactly 995 products is approximately **0.1759** or **17.59%**.


## Probability of Multiple Events

So far we have only considered $P(D|M)$ where the data is a single event. However, it is more common to be have multiple data points, and we'd like to know the relative probability of that specific dataset vs other dataset we may have sampled.

### Law of Probability and Independent Events

First we need to know the law of probability and independent events... How independence is not time series. How we typically add log prob instead of multiply.

### Calculating the Relative Probability of Multiple Events

With that background we can simulate the probability of a multiple events. Assume we are rolling dice out of a cup and we have four dice. We'll use the exact probabilities of getting each total for convenience... Let's assume we rolled the dice out of the cup five times, and got 4, 6, 9, 10, 20. The probability of that is relatively straightforward, it is w * x * y * z.

We'd like to understand how uncommon that event is. To calculate this we will simulate many, say thousands, of rolls with a cup of four dice. It will get many different combinations, but for each one we can calculate the probability.

We then sort all the probabilities from smallest to largest, and see where the specific roll, the 4, 6, 9, 10, 20, falls in those probabilities. If if falls somewhere near the middle, we consider it a common roll. If it falls at an extreme end, we may start to suspect we have unusual luck, or possibly that the dice are not fair.


**Note that we probably want to make this into an app**



```{python}
import numpy as np
import matplotlib.pyplot as plt

def roll_three_dice():
    """Simulate rolling three dice and return their sum"""
    return np.sum(np.random.randint(1, 7, size=3))

def get_probability_of_sum(dice_sum):
    """Calculate probability of getting a specific sum with three dice"""
    possibilities = 0
    total_outcomes = 216  # 6^3 possible outcomes
    
    for i in range(1, 7):
        for j in range(1, 7):
            for k in range(1, 7):
                if i + j + k == dice_sum:
                    possibilities += 1
                    
    return possibilities / total_outcomes

def simulate_rolls():
    """Simulate 10 rolls and calculate cumulative log probability"""
    rolls = [roll_three_dice() for _ in range(10)]
    probabilities = [get_probability_of_sum(roll) for roll in rolls]
    
    # Calculate cumulative log probabilities
    log_probs = np.log10(probabilities)
    cumulative_log_probs = np.cumsum(log_probs)
    
    return rolls, cumulative_log_probs

# Perform simulations
num_simulations = 200
all_cumulative_probs = []

for _ in range(num_simulations):
    rolls, cum_probs = simulate_rolls()
    all_cumulative_probs.append(cum_probs)

# Create the plot
plt.figure(figsize=(10, 6))
x = np.arange(1, 11)

# Plot all simulations in darker gray
for probs in all_cumulative_probs:
    plt.plot(x, probs, color='#404040', alpha=0.3)

plt.xlabel('Number of Rolls')
plt.ylabel('Log10 Probability')
plt.title('Cumulative Log Probability of Multiple Three-Dice Rolls')
plt.grid(True)
plt.show()
```



```{shinylive-python}
#| standalone: true
#| viewerHeight: 800

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt

# --- Utility Functions ---

def roll_three_dice():
    """Simulate rolling three dice and return their sum."""
    return np.sum(np.random.randint(1, 7, size=3))

def get_probability_of_sum(dice_sum):
    """Calculate probability of getting a specific sum with three dice."""
    possibilities = 0
    total_outcomes = 216  # 6^3 possible outcomes
    
    for i in range(1, 7):
        for j in range(1, 7):
            for k in range(1, 7):
                if i + j + k == dice_sum:
                    possibilities += 1
                        
    return possibilities / total_outcomes

def simulate_rolls(num_rolls=10):
    """Simulate a series of rolls and calculate cumulative log probability."""
    rolls = [roll_three_dice() for _ in range(num_rolls)]
    probabilities = [get_probability_of_sum(roll) for roll in rolls]
    
    # To handle log(0), replace zero probabilities with a very small number
    probabilities = [p if p > 0 else 1e-10 for p in probabilities]
    log_probs = np.log10(probabilities)
    cumulative_log_probs = np.cumsum(log_probs)
    
    return rolls, cumulative_log_probs

# -------------------------- UI Definition ---------------------------
app_ui = ui.page_fluid(
    ui.h2("Three-Dice Roll Simulations with Cumulative Log Probability"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_select(
                "selectedSim", 
                "Select Simulation to Highlight", 
                choices=[],   # initially empty, will be updated dynamically
                multiple=False,
            ),
            ui.output_text("selectedDetails"),
            ui.hr(),
            ui.input_slider("numSimulations", "Number of Simulations", min=10, max=500, value=100, step=10),
            ui.input_slider("numRolls", "Number of Rolls per Simulation", min=5, max=50, value=10, step=1),
            ui.input_action_button("runSim", "Run Simulations")
        ),
        ui.output_plot("probPlot", height="500px"),
    )
)

# -------------------------- Server Definition -------------------------
def server(input, output, session):
    # Reactive value to store simulations
    simulations = reactive.Value([])
    
    # Reactive: Perform simulations when 'Run Simulations' button is clicked
    @reactive.Effect
    def _run_simulations():
        input.runSim()  # Depend on the runSim button
        num_sim = input.numSimulations()
        num_rolls = input.numRolls()
        new_simulations = []
        for _ in range(num_sim):
            _, cum_probs = simulate_rolls(num_rolls)
            new_simulations.append(cum_probs)
        simulations.set(new_simulations)
        
        # Update the select input choices
        sim_choices = [f"Simulation {i+1}" for i in range(num_sim)]
        ui.update_select(
            "selectedSim",
            choices=sim_choices,
            selected=sim_choices[0] if sim_choices else ""
        )
    
    # Initialize simulations on app start
    @reactive.Effect
    def _initialize():
        input.runSim()  # Trigger initial simulation run
    
    # Plot the simulations, highlighting the selected one
    @output
    @render.plot
    def probPlot():
        sims = simulations()
        num_sim = len(sims)
        if num_sim == 0:
            fig, ax = plt.subplots()
            ax.text(0.5, 0.5, "No simulations to display.\nClick 'Run Simulations' to start.", 
                    horizontalalignment='center', verticalalignment='center', fontsize=12)
            ax.axis('off')
            return fig
        
        num_rolls = len(sims[0])
        x = np.arange(1, num_rolls + 1)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Plot all simulations in light gray
        for probs in sims:
            ax.plot(x, probs, color='#D3D3D3', alpha=0.5)
        
        # Highlight the selected simulation
        selected = input.selectedSim()
        if selected:
            try:
                sim_index = int(selected.split()[-1]) - 1
                if 0 <= sim_index < num_sim:
                    selected_probs = sims[sim_index]
                    ax.plot(x, selected_probs, color='red', linewidth=2.5, label=selected)
            except (IndexError, ValueError):
                pass
        
        ax.set_xlabel('Number of Rolls')
        ax.set_ylabel('Cumulative Log10 Probability')
        ax.set_title('Cumulative Log Probability of Multiple Three-Dice Roll Simulations')
        ax.grid(True)
        if selected and 0 <= sim_index < num_sim:
            ax.legend()
        
        plt.tight_layout()
        return fig
    
    # Display details of the selected simulation
    @output
    @render.text
    def selectedDetails():
        sims = simulations()
        selected = input.selectedSim()
        if not selected:
            return "No simulation selected."
        try:
            sim_index = int(selected.split()[-1]) - 1
            if sim_index < 0 or sim_index >= len(sims):
                return "Selected simulation is out of range."
            # For demonstration, display the cumulative log probability at the last roll
            final_log_prob = sims[sim_index][-1]
            return f"{selected} Final Cumulative Log10 Probability: {final_log_prob:.4f}"
        except (IndexError, ValueError):
            return "Invalid selection."

app = App(app_ui, server)
```




### Comparison to Traditional Hypothesis Testing




## Summary

What we intended to show here is we can build a model of a process, and use that model to determine how probable any outcome of the process is. We also see that the reliability of that estimate is related to the total number of samples from the process, with more samples leading to more reliable estimates.

## Wait Not so Fast

You may have a thought lingering in the back of your brain - why am I trusting you that your dice rolling model represents reality? Well, in general you shouldn't trust any model. This is where real data is incredibly important. Preferably we'd have the data from real dice rolls, and although we shouldn't expect a perfect match, we'd be able to at least get an intuition for whether the model was reasonable. Since this problem was so simple, and is relatively easy to verify analytically, we skipped this otherwise important step.

## Wait, One More!

You may also have asked yourself - why can't (or when should) I just use the real data to find the probability of an event? This would use the same technique as before, except the data would give count/frequency of the event divided by the total number of observations.

The answer to that is - if you have enough data, you should do it that way! For example, if you've observed something about a dozen or more times in a dataset, dividing the count/frequency of that event by the total number of observations will give you quite a good estimate for its probability, given the same conditions as the dataset. It's more complicated if you've only observed the event a couple times, and obviously impossible if you've observed it zero times. It's also not possible if you want to make a change to the conditions that were used to generate the dataset... (discussion of uncertainty in those estimates at low counts????????, appendix material????)

It's quite common to be interested in the likelihood of an event in the tails (the far ends) of a distribution, however this is also where we need the most caution. Generally we will use some knowledge about the problem and the kind of data it is likely to produce combined with some sample of data to ground-truth the model parameters... However, since the tails of the distribution are rarely or never observed, we need a lot of caution and humility if we try to predict them.

