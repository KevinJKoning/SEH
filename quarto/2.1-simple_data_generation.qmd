---
title: Data Generation
format: html
filters:
  - shinylive
---

## Data Generation with Dice

We'd prefer not to spend too much time on toy examples, however, there are a lot of benefits to starting with something that is intuitive and simple. Subsequently we'll use rolling dice as our first example of a data generating process. It is also convenient that the mathematical model we'll use is an awfully good approximation of the real data generating process, so long as you're OK with ignoring all the physical bouncing of the dice and are content with just the result after a roll.

Play around with the two inputs/parameters of the dice rolling app below, the number of dice and the number of rolls. Note how a larger number of rolls seems to give us smoother and more consistent results.

```{shinylive-python}
#| standalone: true
#| viewerHeight: 550

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt

app_ui = ui.page_fluid(
    ui.h2("Dice Rolling Demo"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_slider("numDice", "Number of Dice", min=1, max=10, value=2, step=1),
            ui.input_slider("numRolls", "Number of Rolls", min=1, max=10000, value=100, step=1),
        ),
        ui.output_plot("dicePlot", height="400px"),
    ),
)

def server(input, output, session):
    # Define a reactive calculation that depends on numDice and numRolls
    @reactive.Calc
    def dice_sums():
        return [
            np.random.randint(1, 7, input.numDice()).sum()
            for _ in range(input.numRolls())
        ]

    @output
    @render.plot
    def dicePlot():
        current_sums = dice_sums()
        fig, ax = plt.subplots()

        unique_sums, counts = np.unique(current_sums, return_counts=True)
        ax.bar([str(s) for s in unique_sums], counts, color="steelblue")

        ax.set_title("Frequency of Dice Totals")
        ax.set_xlabel("Dice Total")
        ax.set_ylabel("Frequency")
        plt.xticks(rotation=90)

        return fig

app = App(app_ui, server)
```

## Dice Totals Probability

Our goal here is not to think too much about the data generating process or the model (that comes later!), what we really want to know now is the likelihood of a given dice total given a particular dice model. To estimate the probability $P(E)$ of an event $E$, we can use the relative frequency approach. This involves counting the number of occurrences of the event E and dividing it by the total number of trials. For example, if we observed a total of twelve occur in 40 out of 5,000 dice rolls, the probability estimate is:

$$
P(E) \approx \frac{\text{Number of times event } E \text{ occurs}}{\text{Total number of trials}} = \frac{40}{5000} = 0.008
$$

The accuracy of this estimate depends on the total number of trials as governed by the Law of Large Numbers. The standard error, which gives a measure of uncertainty in the estimate, is inversely proportional to the square root of the total number of trials. Specifically, the error in our estimate is:

$$
P_{\text{error}} \propto \frac{1}{\sqrt{N_{\text{total}}}}
$$

Now I know you're smart, and you're saying to yourself, I can figure out the *exact* probability of rolling a certain dice total. Of course you can for this example - but you probably can't for more realistic examples, and we want to learn techiques that work well in reality. In general, if you are concerned with the quality of an estimate with this approach, just rerun the data generating process and see if the outcome changes meaningfully - if it does, increase the number of times we run the data generating process until the output is stable enough for your application.

::: callout-note
Throughout this primer there will be several opportunities for exact/analytical solutions, but we will generally ignore them. Instead we will choose computation whenever it is plausible. Why? It's simply a lot faster than figuring out some unknown depth of analysis, and we can usually have more confidence in the results. (Some may know an essay called the 'Bitter Lesson', which I think has a strong engineering correlarly...). Be assured that solving problems through raw computation has it's limits - there's no way to compute through a bad algorithm, and often the right next step in that situation is to gain a more fundamental understanding through analysis. But we're professionals in a hurry, we choose computation when it's plausible.
:::

## Summary

What we intended to show here is we can build a model of a process, and use that model to determine how probable any outcome of the process is. We also see that the reliability of that estimate is related to the total number of samples from the process, with more samples leading to more reliable estimates.