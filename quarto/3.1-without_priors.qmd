---
title: Without Priors
format: html
filters:
  - shinylive
---

## Preview

We finally flip to $\mathcal{L}(M|D)$ the likelihood of a [model]{style="text-decoration: underline;"} given the [data]{style="text-decoration: underline;"}. In practice, we typically find $\mathcal{L}(M|D)$ so that we can find the *best* parameter values for our chosen model type, although it could also be used to select between model types. We will describe what *best* is soon.

Like before, we begin with a simple dice model as we consider it to be an intuitive subject. We then work forward in generally the same order as the first half of the primer. We work with probability distributions and how to find the most likely parameters given the observed data. We pause to examine how likely we are to calculate one set of parameters when the true process has another set of parameters. As usual we use computation to avoid misunderstood analytical solutions.

Throughout the chapter assume no prior knowledge of what the best model parameters may be - although in an app where you can guess and check you are probably not guessing randomly, which is already a hint at what a prior would be. In the next chapter we'll formalize how to find optimal models when we have prior information about the parameter values. In more statistical terms, this chapter utilizes a Frequentist perspective and the next a Bayesian perspective.

## Guessing the Best Model Parameter 

In part one we wanted to understand the probability of the data based on a fixed model of a data generating process. In part two we use the data to find the most likely model of the data generating process, which requires use to calculate $P(D|M)$. Intuitively, this is just a model that generates or predicts data that is similar to our observed data. Subsequently we start with an intuitive excercise before diving further into the technical details. 

The simple app below lets you select a model parameter, the number of dice to roll, such that you can see if your selection makes it match the data better or worse. See if you can find a parameter value that does a particularly good job of matching the data.

```{shinylive-python}
#| standalone: true
#| viewerHeight: 550

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt

# --- Precompute the "permanent" histogram for 7 dice, 10,000 rolls ---
FIXED_NUM_DICE = 7
FIXED_NUM_ROLLS = 10000

fixed_sums = [np.random.randint(1, 7, FIXED_NUM_DICE).sum() for _ in range(FIXED_NUM_ROLLS)]
fixed_unique_vals, fixed_counts = np.unique(fixed_sums, return_counts=True)

app_ui = ui.page_fluid(
    ui.h2("Dice Rolling Demo"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_slider(
                "num_dice",
                "Number of Dice (1–10)",
                min=1,
                max=10,
                value=2,
                step=1
            ),
        ),
        ui.output_plot("dicePlot", height="400px"),
    ),
)

def server(input, output, session):
    @reactive.Calc
    def user_sums():
        # Always roll the user-selected dice 10,000 times
        N_ROLLS = 10000
        n_dice = input.num_dice()
        rolls = [np.random.randint(1, 7, n_dice).sum() for _ in range(N_ROLLS)]
        return rolls

    @output
    @render.plot
    def dicePlot():
        # Get the user’s histogram
        sums = user_sums()
        user_unique_vals, user_counts = np.unique(sums, return_counts=True)
        
        # Determine the union of x-values (totals) so both histograms can share the same axis
        all_x = np.arange(
            min(fixed_unique_vals[0], user_unique_vals[0]),
            max(fixed_unique_vals[-1], user_unique_vals[-1]) + 1
        )
        
        # Convert the unique/value arrays to dictionaries for easy indexing
        fixed_map = dict(zip(fixed_unique_vals, fixed_counts))
        user_map = dict(zip(user_unique_vals, user_counts))
        
        # Pull out frequency or 0 if total not present in the distribution
        fixed_freqs = [fixed_map.get(x, 0) for x in all_x]
        user_freqs  = [user_map.get(x, 0) for x in all_x]
        
        # Plot
        fig, ax = plt.subplots()
        
        # Bar chart for the fixed 7-dice histogram
        ax.bar(all_x, fixed_freqs, color="lightblue", alpha=0.6, label="Fixed Dice")
        
        # Overlay user histogram as points
        ax.scatter(all_x, user_freqs, color="red", marker="o", label="User Selected Dice")
        
        ax.set_title("Update the Input Parameter to Match Observations")
        ax.set_xlabel("Dice Total")
        ax.set_ylabel("Frequency")
        ax.legend()
        
        # Make x-axis tick at every possible total
        plt.xticks(all_x, rotation=90)
        
        return fig

app = App(app_ui, server)
```

I'm guessing you succeeded. We want to be able to do that automatically, and with many more parameters, such that if we have data but aren't certain about the model generating it, we can work in 'reverse' to find a likely model of the real world data generating process.

## Likelihood

In the previous dice example, we were just eyeballing the right model parameters to maximize the probability of observing our data under the model. We’d like a more consistent and mathematical way to achieve the same intent, which is called a **likelihood** function. In generic form, it looks like this:

$$
\mathcal{L}(\theta \mid \mathbf{y}) = \prod_{i=1}^{N} P(y_i \mid \theta)
$$ 

1. $\mathcal{L}(\theta \mid \mathbf{y})$: The likelihood of the model parameter[s] ($\theta$) given the observed data ($\mathbf{y}$).

2. $P(y_i \mid \theta)$: The probability of a data point ($y_i$) given the model parameter[s] ($\theta$). This is the individual probability density for continuous functions or probability for discrete functions. 

3. $\prod_{i=1}^{N}$: This is the product operation, which multiplies the individual probabilities $P(y_i \mid \theta)$ across all $N$ data points in the dataset. This assumes that the data points are independent. In practice this is typically replaced by the addition of log probabilities, as previously described.

In practice, calculating $P(y_i \mid \theta)$ generally requires making an informed assumption about which named parametric probability distribution best represents your data. We've tried to make the point that reality does not consist of only the *named* probability distributions, however, we use them because they allow for efficient probability calculations, and we can generally choose a named probability distribution that fits the problem as well as practically needed.

In the dice app above, the likelihood of the number of dice parameter being a value of 1, 2, or 3 based on the data shown is approximately zero ($\mathcal{L}(\theta \in {1,2,3} \mid \mathbf{y}) \approx 0$). In the next section we'll make the calculations more precisely.

## Maximum Likelihood Estimation with Discrete Data

It is common to consider the best model to be the one that maximizes the likelihood of the observed data. This is called Maximum Likelihood Estimation (MLE). The difficulty in finding the maximum likelihood estimate varies substantially depending on the problem. For simpler problems there is often a derived analytical solution. We will touch on these briefly, but we hold to one of our general themes, which is that we prefer computational solutions that can handle real-world problems.

We introduced the binomial distribution in our chapter on discrete probability distributions. There we worked a problem in which we could find the exact probability of the data given a model, P(D|M), where the model was the binomial distribution with a given value of the p parameter. However, we now want to work in the other direction, $\mathcal{L}(M|D)$, in which we find the value of the p parameter with the maximum likelihood.

Although the app below does not automatically give you the maximum likelihood estimate, it will hopefully make it easy for you to approximate the value. Pick several p values you think are reasonable and for each select 'Add to plot'.

```{shinylive-python}
#| standalone: true
#| viewerHeight: 700

import numpy as np
import matplotlib.pyplot as plt
from shiny import App, ui, reactive, render
from scipy.stats import binom

app_ui = ui.page_fluid(
    ui.h3("In four batches of 1,000 products, we have 992, 995, 989, and 998 pass, what is the most likely pass probability?"),
    
    # Input row
    ui.row(
        ui.column(
            4,
            ui.input_numeric(
                "pInput", "Enter probability (p):",
                value=0.993, min=0, max=1, step=0.001
            ),
        ),
        ui.column(
            4,
            ui.br(),
            ui.br(),
            ui.input_action_button("addBtn", "Add to Plot"),
            ui.input_action_button("resetBtn", "Reset", class_="btn-danger ms-2"),
        ),
        ui.column(
            4,
            ui.h4("MLE Estimate of p:"),
            ui.output_text("mleOutput"),
        ),
    ),
    
    ui.br(),
    
    # Plots
    ui.row(
        ui.column(
            6,
            ui.output_plot("batchPlot"),
        ),
        ui.column(
            6,
            ui.output_plot("probPlot"),
        ),
    ),
)

def server(input, output, session):
    # Data for the four batches
    batch_data = [(992, 1000), (995, 1000), (989, 1000), (998, 1000)]  # (successes, trials)
    
    # Store the user-selected probabilities and their log-likelihoods
    stored_probs = reactive.Value([])
    stored_lls = reactive.Value([])
    
    # Calculate MLE estimate
    total_success = sum(x[0] for x in batch_data)
    total_trials = sum(x[1] for x in batch_data)
    mle_p = total_success / total_trials
    
    @output
    @render.text
    def mleOutput():
        return f"p = {mle_p:.6f}"
    
    # Reset function
    @reactive.Effect
    @reactive.event(input.resetBtn)
    def _():
        stored_probs.set([])
        stored_lls.set([])
    
    # Add new probability when button is clicked
    @reactive.Effect
    @reactive.event(input.addBtn)
    def _():
        p = input.pInput()
        if p not in stored_probs.get():
            probs = list(stored_probs.get())
            probs.append(p)
            stored_probs.set(probs)
            
            # Calculate cumulative log likelihood for this p
            total_ll = 0
            batch_lls = []
            for success, trials in batch_data:
                ll = binom.logpmf(success, trials, p)
                total_ll += ll
                batch_lls.append(total_ll)
            
            lls = list(stored_lls.get())
            lls.append((p, batch_lls))
            stored_lls.set(lls)
    
    @output
    @render.plot
    def batchPlot():
        fig, ax = plt.subplots(figsize=(8, 6))
        
        for p, batch_lls in stored_lls.get():
            ax.plot(range(1, 5), batch_lls, 'o-', label=f'p={p:.3f}')
        
        ax.set_xlabel('Batch Number')
        ax.set_ylabel('Cumulative Log Probability')
        ax.set_title('Cumulative Log Probability by Batch')
        ax.grid(True)
        
        # Set x-axis ticks to integers
        ax.set_xticks(range(1, 5))
        
        if stored_lls.get():
            ax.legend()
        
        return fig
   
    @output
    @render.plot
    def probPlot():
        fig, ax = plt.subplots(figsize=(8, 6))
        
        if stored_lls.get():
            # Sort the data by probability before plotting
            sorted_data = sorted(stored_lls.get(), key=lambda x: x[0])
            probs = [x[0] for x in sorted_data]
            final_lls = [x[1][-1] for x in sorted_data]
            
            ax.plot(probs, final_lls, 'o-')
            ax.axvline(mle_p, color='red', linestyle='--', 
                      label=f'MLE (p={mle_p:.3f})')
        
        ax.set_xlabel('Probability (p)')
        ax.set_ylabel('Total Log Probability')
        ax.set_title('Total Log Probability vs. p')
        ax.grid(True)
        if stored_lls.get():
            ax.legend()
        
        return fig

app = App(app_ui, server)
```

Let's breakdown how the likelihood was calculated for one of the datapoints. First, we needed to determine a probability distribution that represents our data. Because we have a fixed number of trials and probability of success for each trial, the Binomial probability distribution was a good choice.

### Reminder of Binomial Probabilities

Next, let's remind ourselves how to calculate the probability of an observation that follows the Binomial probability distribution:

$$
P(X = k | n, p) = \binom{n}{k} p^k (1 - p)^{n - k}
$$

where:

* $k$ is the observed number of successes in $n$  trials.
* $p$ is the probability of success in each trial.

Our first data point is 992 successes, which equals k, out of 1,000 trials, which equals n. The best value of p is what we are unsure about, and our current strategy is to strategically try some values to try to understand the problem. Let's assume we tried p = 0.995 as a reasonable guess. The calculation is:

$$
P(X = 992 | n = 1000, p = 0.995) =
\binom{1000}{992} (0.995)^{992} (0.005)^8 = 0.0652
$$

The result is that the 992 data point has a probability of 0.0652, if we assume n=1000 and p=0.995. That value is about -2.73 using the natural log or -1.19 using log base 10. In the app above, if you select p=0.995 and select 'Add to Plot', the value of the first point, which corresponds to k=992, has a value of about -2.73.

### Difference between $\mathcal{L}(M|D)$ and P(D|M)

Now you should be asking yourself - what is the difference between what we are doing here and what we did in the first half when we calculated P(D|M)? And the answer is that up until this step - nothing. So where does the difference come in?

The difference is that we use the probability of the data to determine the likelihood of the model in comparison to other possible models. We then optimize the parameters until we find the best model, i.e the one with the Maximum Likelihood Estimate. So in summary, the calculation of the probabilities is the same - the difference is we use an optimization strategy to find the best $\mathcal{L}(M|D)$.

### A Subtly Good Strategy

Playing around with the app you should be able to see that the chart on the right, the 'Total Log Probability vs p.' has an obvious peak. What we want are parameter values that are the most probable, i.e. the ones with the largest total log probability. Here we can fairly easily pick random values, and maybe use some hints from the slope of the graph, to find a good estimate of p. That strategy to find the most probable model is actually not a bad one - a state of the art method is effectively a very sophisticated version of that same strategy.

### Analytical Solution

For the Binomial distribution there's actually a simple analytical solution, and while it may seem simple in hindsight, the proper derivation is maybe more complex than you'd expect... The basic idea is that the derivative of the 'Total Log Probability vs p.' chart will equal zero at the maximum probability. After a brief drum roll we can reveal that the most likely estimate of p is ....... just the average success rate. More precisely, the successes divided by the total n, e.g. (992 + 995 + 989 + 998)/(1,000 + 1,000 + 1,000 + 1,000).

Although we mostly avoid them, analytical solutions can be very useful. For one they are typically very fast to compute. And secondly, they can be a nice verification that approximate/numerical methods converge to reasonable solutions, for at least some set of circumstances.

## Computational Strategies for finding the Maximum Likelihood Estimate

Analytical solutions are not common for real-world problems, so we consider some computational strategies for finding the Maximum Likelihood Estimate.

### Grid Search

Grid search simply divides up the parameter space (i.e. the possible parameter values) into a discrete number of values to check. For example, if we are trying to estimate $p$ in a simple model based on the binomial distribution, it can range from 0 to 1, so we could try the values 0.01, 0.02 ... 0.98, and 0.99. Of the 99 likelihood estimates we calculate, we simply pick the p value associated with the largest likelihood. 

The grid search estimate for the binomial example would be denoted as $\hat{p}_{\text{grid}}$, which is the value of $p$ from the grid $G$ that maximizes the likelihood (or log-likelihood):

$$
\hat{p}_{\text{grid}} = \arg\max_{p_i \in G} l(p_i \mid n, k)
$$

This notation means: "$\hat{p}_{\text{grid}}$ is the value of $p_i$, chosen from the set $G$, that maximizes the function $l(p_i \mid n, k)$."

Grid search is attractive due to its simplicity. However, it doesn't scale well if you need to estimate multiple parameters (high dimensionality) because the plausible number of combinations increases exponentially (also known the curse of dimensionality). For example, if may believe we can reasonably estimate a parameter by picking a minimum and a maximum value, dividing the space between into 100 values to check, and finding the parameter value with the maximum likelihood. With two parameters, this is quite feasible, 100^2, or 10,000. Three parameters is still quite feasible, at 100^3 or 1,000,000 combinations, with modern computers - but we can see where this is going. Any large number of parameters will be intractable. 

### Gradient Ascent (or Descent on the Negative Log-Likelihood)

In our manual estimation of the Maximum Likelihood with discrete data, we created a chart that had an obvious peak at the Maximum Likelihood Estimate. If we want to find that peak we simply need to 'walk' up the hill. If the slope decreases near the top it may be a hint we should slow down to not overshoot the peak. This is the idea of using gradients/derivatives to make our calculation more efficient.

We aim to minimize $min_{\theta} f(\theta)$ by computing the gradient of $f(\theta)$ with respect to $\theta$:

$$
\nabla f(\theta) = \left[ \frac{\partial f}{\partial \theta_1}, \frac{\partial f}{\partial \theta_2}, \dots, \frac{\partial f}{\partial \theta_n} \right]
$$

This gradient points in the direction of the steepest ascent. We update our previous estimate by taking a step with a step size with learning rate $\eta$:

$$
\theta^{(t+1)} = \theta^{(t)} - \eta \nabla f(\theta^{(t)})
$$

where $t$ is the iteration index.

The use of gradients/derivatives forms a core piece of most modern optimization methods. The methods that use these gradients/derivatives are so effective, practitioners will go to great lengths to ensure that the gradients/derivatives can be calculated for their problem. This fact has given birth to many 'autograd' libraries that efficiently find derivatives in very complex problem domains. Modern neural networks are possible due to efficient matrix multiplication and gradient/derivative estimation.

## Maximum Likelihood Estimate with Continuous Data

We move onto continuous data and continuous probability distributions, but with the same goal of finding the model parameters that maximize the likelihood of the observed data. The methods remain the same. The only difference we should keep in mind is that when we calculate $P(y_i \mid \theta)$, with a continuous probability distribution, it is a probability density, and not a true probability. However, since probability densities can still be used to compare relative probability, and we are only trying to find the model parameter values that are the most likely relative to all other possibilities, this nuance has little practical impact.

### Normal Distribution with MLE Estimate

The following is a very similar app to what we saw earlier that just calculated with likelihood of the data. However, this time we also have ability to find the most likely model to explain the data, i.e the Maximimum Likelihood Estimate *MLE* ...

```{shinylive-python}
#| standalone: true
#| viewerHeight: 700

import math
import numpy as np
import matplotlib.pyplot as plt
from shiny import App, ui, reactive, render

app_ui = ui.page_fluid(
    ui.h2("Likelihood Calculation"),

    # Row 1: Sliders
    ui.row(
        ui.column(
            4,
            ui.input_slider(
                "muInput", "Mean (μ):",
                min=50, max=150, value=100, step=0.1
            ),
        ),
        ui.column(
            4,
            ui.input_slider(
                "varInput", "Variance (σ²):",
                min=1, max=200, value=10, step=1
            ),
        ),
        ui.column(
            4,
            ui.input_slider(
                "nInput", "Number of samples:",
                min=1, max=100, value=10, step=1
            ),
        ),
    ),

    ui.br(),

    # Row 2: Buttons, current data, and log-likelihood
    ui.row(
        ui.column(
            2,
            ui.input_action_button("mleBtn", "MLE"),
        ),
        ui.column(
            2,
            ui.input_action_button("newSampleBtn", "NEW SAMPLE"),
        ),
        ui.column(
            4,
            ui.h4("Current Data (Y):"),
            ui.output_text_verbatim("dataText"),
        ),
        ui.column(
            4,
            ui.h4("Log-Likelihood:"),
            ui.output_text("llOutput"),
        ),
    ),

    ui.br(),

    # Plots
    ui.row(
        ui.column(6, ui.output_plot("normalPlot", height="400px")),
        ui.column(6, ui.output_plot("cumLogProbPlot", height="400px"))
    ),
)

def server(input, output, session):
    # Initialize data with 10 random points
    data_vals = reactive.Value(
        np.random.normal(loc=100, scale=np.sqrt(10), size=10)
    )

    # Generate a new sample when 'NEW SAMPLE' is pressed
    @reactive.Effect
    @reactive.event(input.newSampleBtn)
    def _():
        n = input.nInput()
        data_vals.set(
            np.random.normal(loc=100, scale=np.sqrt(10), size=n)
        )

    # Display the current data
    @output
    @render.text
    def dataText():
        y = data_vals()
        return ", ".join(str(round(val, 1)) for val in y)

    # When 'MLE' is clicked, update muInput and varInput to MLE estimates
    @reactive.Effect
    @reactive.event(input.mleBtn)
    def _():
        y = data_vals()
        n = len(y)
        mle_mean = np.mean(y)
        mle_var = np.sum((y - mle_mean)**2) / n
        session.send_input_message("muInput", {"value": mle_mean})
        session.send_input_message("varInput", {"value": mle_var})

    # Reactive expression for log-likelihood
    @reactive.Calc
    def log_likelihood():
        y = data_vals()
        mu = input.muInput()
        var = input.varInput()
        n = len(y)
        if var <= 0:
            return float("nan")
        term1 = -0.5 * n * math.log(2 * math.pi * var)
        term2 = -0.5 * np.sum((y - mu)**2) / var
        return term1 + term2

    # Show the log-likelihood
    @output
    @render.text
    def llOutput():
        ll = log_likelihood()
        return str(round(ll, 2))

    # Plot the normal PDF and data points
    @output
    @render.plot
    def normalPlot():
        y = data_vals()
        mu = input.muInput()
        var = input.varInput()
        sigma = math.sqrt(var)

        x_min = min(y) - 3 * sigma
        x_max = max(y) + 3 * sigma
        x_vals = np.linspace(x_min, x_max, 200)
        pdf_vals = (1.0 / (sigma * np.sqrt(2 * math.pi))) * np.exp(
            -0.5 * ((x_vals - mu) / sigma)**2
        )

        fig, ax = plt.subplots(figsize=(6, 4))
        ax.plot(
            x_vals, pdf_vals,
            color="blue",
            label=f"Normal PDF (μ={round(mu,1)}, σ²={round(var,1)})"
        )

        # Scatter the data at y=0 with some jitter
        jittered = y + np.random.uniform(-0.1, 0.1, size=len(y))
        ax.scatter(jittered, np.zeros_like(y), color="darkgreen", alpha=0.7, label="Data points")

        ax.axvline(mu, color="gray", linestyle="--")
        ax.set_title("Normal PDF vs. Observed Data")
        ax.set_xlabel("Y")
        ax.set_ylabel("Density")
        ax.legend()
        ax.set_ylim(bottom=0)

        return fig

    # Plot the cumulative log probability
    @output
    @render.plot
    def cumLogProbPlot():
        y = data_vals()
        mu = input.muInput()
        var = input.varInput()
        sigma = math.sqrt(var)

        # Sort data points for plotting
        sorted_indices = np.argsort(y)
        sorted_y = y[sorted_indices]
        
        # Calculate log probabilities
        log_probs = -0.5 * np.log(2 * math.pi * var) - 0.5 * ((sorted_y - mu) / sigma)**2
        cum_log_probs = np.cumsum(log_probs)

        fig, ax = plt.subplots(figsize=(6, 4))
        ax.plot(sorted_y, cum_log_probs, 'b-', marker='o')
        ax.set_title("Cumulative Log Probability")
        ax.set_xlabel("Data Points")
        ax.set_ylabel("Cumulative Log Probability")
        ax.grid(True)

        return fig

app = App(app_ui, server)
```


### Log Normal



### Linear Regression


## Machine Learning

### Loss Function

A loss function, denoted as $L$, is typically computed as the difference between the true target values $y$ and the predicted values $\hat{y}$ The generic form of a loss function can be expressed as:

$$
L(y, \hat{y}) = \frac{1}{N} \sum_{i=1}^{N} \ell(y_i, \hat{y}_i)
$$

#### Variables:

-   $y_i$: The true value for the (i)-th data point.
-   $\hat{y}_i$: The predicted value for the (i)-th data point.
-   $\ell(y_i, \hat{y}_i)$: The individual error for the (i)-th data point defined by the loss function.
-   $N$: The total number of data points.

The function $\ell(y_i, \hat{y}_i)$ depends on the task.

### Comparison to Likelihood Function

Likelihood functions are always based in probability/statistical theory (loss functions may or may not be). We use likelihood to find the best statistical model, specifically by finding the Maximum Likelihood Estimate (MLE). We will explore these more in the second half of the primer, $\mathscr{L}(M|D)$.

## Summary

To find the most likely model 
Finding the most likely model, i.e. using Maximum Likelihood Estimation, to explain 







## Segway

The following is a nice segway to the machine learning section, but should be at the very end of the chapter.

Maximum Likelihood Estimation is not the only method to find optimal model parameters, although it is the standard for statistical models.

::: callout-note
## Loss Functions

Likelihood is a specific form of a **loss function**. Likelihood is rooted in probability, but a loss function does not need to be. Loss functions in machine learning are what likelihood functions are in statistics. In generic form they look like this:

$$
\mathcal{L}(\mathbf{y}, \hat{\mathbf{y}}) = \frac{1}{N} \sum_{i=1}^{N} \ell(y_i, \hat{y}_i)
$$

1.  $\mathcal{L}(\mathbf{y}, \hat{\mathbf{y}})$: This represents the overall loss function, which measures the difference between the true values $\mathbf{y}$ and the predicted values $\hat{\mathbf{y}}$. It aggregates the individual losses across all data points.

2.  $\ell(y_i, \hat{y}_i)$: This is the individual loss for a single data point $i$. It can take different forms depending on the type of problem. 

3.  $\frac{1}{N} \sum_{i=1}^{N}$: This is the averaging operation, which sums up the individual losses $\ell(y_i, \hat{y}_i)$ across all $N$ data points in the dataset and divides by $N$ to compute the average loss. This helps ensure that the loss function is independent of the dataset size.
:::

We introduce loss functions here but will apply them next chapter??

## Methods

Before we dive too deep into the details, we are going to take a moment to reflect on what we're attempting to do and common techniques to do it...

When we were just generating data, it was obvious what variables went into the model, and what data came out of the model. However, we should do a better job of defining that now. Part of the issue here is that many names are used for many applications. We will call inputs predictor/feature variables, and we will call the outputs the outcome/target variables...

## Note in 3.2 we will go into the likelihood calculation itself


## Traditional Linear Regression

Single-variable linear regression aims to model the relationship between a single independent variable \( x \) and a dependent variable \( y \) using a linear equation:

\[
y = mx + b
\]

where:
- \( m \) (slope) represents the rate of change of \( y \) with respect to \( x \),
- \( b \) (intercept) is the value of \( y \) when \( x = 0 \).

## Least Squares Method

The goal is to minimize the sum of squared residuals:

\[
J(m, b) = \sum_{i=1}^{n} (y_i - (mx_i + b))^2
\]

where \( (x_i, y_i) \) are the given data points.

### Solving for \( m \) and \( b \)

To find \( m \) and \( b \) analytically, we take the partial derivatives of \( J(m, b) \) and set them to zero:

#### Step 1: Compute the slope \( m \)

\[
m = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2}
\]

where \( \bar{x} \) and \( \bar{y} \) are the means of \( x \) and \( y \):

\[
\bar{x} = \frac{1}{n} \sum x_i, \quad \bar{y} = \frac{1}{n} \sum y_i
\]

#### Step 2: Compute the intercept \( b \)

\[
b = \bar{y} - m \bar{x}
\]

### Final Model

Thus, the best-fitting line is:

\[
y = mx + b
\]

where \( m \) and \( b \) are computed using the formulas above.

This method provides an exact solution without requiring iterative optimization, making it efficient for small datasets.


### Notes

TODO: We should maintain approximately the same rate of callouts?
