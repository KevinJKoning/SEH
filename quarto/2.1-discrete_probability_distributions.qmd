---
title: Discrete Probability Distributions
format: html
filters:
  - shinylive
---

## Preview

In the first half of the primer we focus on $P(D|M)$, the probability of the [data]{style="text-decoration: underline;"} given a [model]{style="text-decoration: underline;"} of a data generating process. This first chapter considers only processes with discrete (in contrast with continuous) outputs. We use a model of dice as our first example as it is hopefully an intuitive subject. We then introduce more *discrete probability distributions* as models of other idealized processes. For the first half of the primer we will not question our models, we will consider them as set/frozen and just allow them to generate data for us, assuming that they represent the data generating process of interest.

Once we have have some discussion of models under our belt, we will change our focus to the probability of data. For any model we can use the relative frequency of an event to approximate the events probability. We will show how the accuracy of this probability estimate increases with the number of samples. Where an analytical solution of $P(D|M)$ is available, we will also compare exact probabilities to those estimated from relative frequency.

We then shift to the probability of multiple events based on the laws of probability for independent events. We show how we can use computation to calculate the relative probability of a specific series of events by comparing it to a multitude of randomly generated series of events. We use the example of finding the probability that a die is weighted (unfair) after an observed series of rolls. This is our more intuitive approach to hypothesis testing.

## Models of Discrete Data Generating Processes

### A Dice Total Model

We'd prefer not to spend too much time on toy examples, however, there are a lot of benefits to starting with something that is intuitive and simple. Subsequently we'll use rolling dice as our first example of a data generating process. It is also convenient that the mathematical model we'll use is a good approximation of the real data generating process, so long as you're OK with ignoring all the physical bouncing of the dice and are content with just the result after a roll.

A dice model is built into the app displayed beneath this paragraph. It will simulate rolling the number of dice you specify, as if you threw them out of a cup all at once, and total the value on those dice from the cup, which is considered one roll. Additionally, it will repeat rolling that cup of dice the number of times you specify, and summarize the results on a histogram. Play around with the two inputs/parameters of the dice rolling app below, the number of dice and the number of rolls.

```{shinylive-python}
#| standalone: true
#| viewerHeight: 550

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt

app_ui = ui.page_fluid(
    ui.h2("Dice Rolling App"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_slider("numDice", "Number of Dice", min=1, max=10, value=2, step=1),
            ui.input_slider("numRolls", "Number of Rolls", min=1, max=10000, value=100, step=1),
        ),
        ui.output_plot("dicePlot", height="400px"),
    ),
)

def server(input, output, session):
    # Define a reactive calculation that depends on numDice and numRolls
    @reactive.Calc
    def dice_sums():
        return [
            np.random.randint(1, 7, input.numDice()).sum()
            for _ in range(input.numRolls())
        ]

    @output
    @render.plot
    def dicePlot():
        current_sums = dice_sums()
        fig, ax = plt.subplots()

        unique_sums, counts = np.unique(current_sums, return_counts=True)
        ax.bar([str(s) for s in unique_sums], counts, color="steelblue")

        ax.set_title("Frequency of Dice Totals")
        ax.set_xlabel("Dice Total")
        ax.set_ylabel("Frequency")
        plt.xticks(rotation=90)

        return fig

app = App(app_ui, server)
```

Hopefully you've noted how a larger number of rolls seems to give us smoother and more consistent results. We will revisit this point more precisely in a later section.

### Discrete Probability Distributions as Models of Data Generating Processes

In the last section, we used dice rolling as our data generating process, however there are other discrete processes we may be interested in, such as testing 1,000 products that have a 0.999 probability of success each. As you can imagine, when you change the data generating process, the relative frequency (distribution) of the outcomes change. There are a number of discrete processes that are important to statisticians, and they have been formalized into mathematical models called *discrete probability distributions*.

::: callout-note
If you are familiar with discrete probability distributions, you may have expected them to be introduced as a way to find the exact probability of an event, instead of using them to generate data. We will eventually use this feature, but our goal is to more generally introduce models of data generating processes and their associated probability distributions. Only a small number have properties that allow for nice analytical solutions to the probabilities of their data, and we'd prefer not to constrain ourselves to thinking in only an analytical (as opposed to computational) framework.
:::

Initially we want to think about discrete probability distributions in the same way we thought about our dice model, that it is a model that will generate random events from a data generating process of interest. Below are a couple examples to illustrate the point.

#### Binomial Distribution

The binomial distribution is a model that represents the number of successes in a fixed number of independent trials, where each trial has two possible outcomes (commonly referred to as “success” and “failure”). The probability of success can range between 0 and 1. In the app below you can recreate something like the product testing scenario recently mentioned. Feel free to play around with the settings/parameters to get a feel for how the probability distribution behaves.

```{shinylive-python}
#| standalone: true
#| viewerHeight: 550

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt
import math

app_ui = ui.page_fluid(
    ui.h2("Binomial Distribution Simulation with Binned Histogram"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_slider(
                "numTrials", 
                "Number of Trials (n)", 
                min=1, 
                max=10000, 
                value=100, 
                step=1
            ),
            ui.input_slider(
                "probSuccess", 
                "Probability of Success (p)", 
                min=0.001, 
                max=0.999, 
                value=0.5, 
                step=0.001
            ),
            # Removed the "Number of Simulations" slider
            # Fixed number of simulations to 10,000
        ),
        ui.output_plot("binomPlot", height="400px"),
    ),
)

def server(input, output, session):
    # Fixed number of simulations
    FIXED_NUM_SIMULATIONS = 10000

    # Reactive expression to generate binomial samples
    @reactive.Calc
    def binomial_samples():
        n = input.numTrials()
        p = input.probSuccess()
        size = FIXED_NUM_SIMULATIONS
        return np.random.binomial(n, p, size)
    
    # Function to determine optimal integer bin width
    def determine_bin_width(data, max_bins=30):
        data_min = data.min()
        data_max = data.max()
        data_range = data_max - data_min + 1  # +1 to include both endpoints
        # Start with bin_width = 1 and increase until the number of bins <= max_bins
        for bin_width in range(1, data_range + 1):
            num_bins = math.ceil(data_range / bin_width)
            if num_bins <= max_bins:
                return bin_width
        return 1  # Fallback to bin_width=1 if all else fails
    
    # Render the binomial distribution plot with limited bins
    @output
    @render.plot
    def binomPlot():
        samples = binomial_samples()
        bin_width = determine_bin_width(samples, max_bins=30)
        
        # Define bin edges based on bin_width
        data_min = samples.min()
        data_max = samples.max()
        bins = np.arange(data_min, data_max + bin_width, bin_width)
        
        # Compute histogram
        counts, bin_edges = np.histogram(samples, bins=bins)
        bin_centers = bin_edges[:-1] + bin_width / 2
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        ax.bar(bin_centers, counts, width=bin_width*0.9, color="steelblue", edgecolor="black", align='center')
        
        ax.set_title("Frequency of Successes in Binomial Simulations", fontsize=16)
        ax.set_xlabel("Number of Successes", fontsize=14)
        ax.set_ylabel("Frequency", fontsize=14)
        #ax.grid(True, axis='y', linestyle='--', alpha=0.7)
        
        # Set x-axis ticks to be at bin centers
        ax.set_xticks(bin_centers)
        
        # To avoid overcrowding, set a maximum number of x-ticks
        if len(bin_centers) > 20:
            step = math.ceil(len(bin_centers) / 20)
            ax.set_xticks(bin_centers[::step])
            ax.set_xticklabels([int(x) for x in bin_centers[::step]], rotation=90)
        else:
            ax.set_xticklabels([int(x) for x in bin_centers], rotation=90)
        
        plt.tight_layout()
        
        return fig

app = App(app_ui, server)
```

#### Poisson Distribution

The Poisson distribution is a model that describes the number of events occurring in a fixed interval of time or space, assuming that the events occur independently and at a constant average rate. For example, it might represent the number of phone calls received by a call center in an hour or the number of cars passing through a toll booth in a minute. The Poisson Distribution is similar to the Binomial distribution, except there are not a fixed number of trials, so there is not an upper limit to the number of events returned by a sample. However, values much larger than the average rate become incredibly unlikely.

```{shinylive-python}
#| standalone: true
#| viewerHeight: 550

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import poisson
import math

# Define the User Interface
app_ui = ui.page_fluid(
    ui.h2("Poisson Distribution Simulation"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_slider(
                "rate_param", 
                "Rate Parameter (λ)", 
                min=0.01, 
                max=10.0, 
                value=1.0, 
                step=0.01
            ),
            ui.input_slider(
                "num_trials",
                "Times to Repeat Sample",
                min=100,
                max=10000,
                value=10000,
                step=100
            )
        ),
        ui.output_plot("poissonPlot", height="400px"),
    )
)

# Define the Server Logic
def server(input, output, session):

    # Reactive expression to get the number of simulations
    @reactive.Calc
    def num_simulations():
        return input.num_trials()

    # Reactive expression to generate Poisson samples
    @reactive.Calc
    def poisson_samples():
        lam = input.rate_param()
        n_trials = num_simulations()
        return np.random.poisson(lam, n_trials)
    
    # Function to determine optimal integer bin width with a maximum number of bins
    def determine_bin_width(data, max_bins=30):
        data_min = data.min()
        data_max = data.max()
        data_range = data_max - data_min + 1  # +1 to include both endpoints
        # Start with bin_width = 1 and increase until the number of bins <= max_bins
        for bin_width in range(1, data_range + 1):
            num_bins = math.ceil(data_range / bin_width)
            if num_bins <= max_bins:
                return bin_width
        return 1  # Fallback to bin_width=1 if all else fails

    # Render the Poisson distribution plot
    @output
    @render.plot
    def poissonPlot():
        samples = poisson_samples()
        lam = input.rate_param()
        
        bin_width = determine_bin_width(samples, max_bins=30)
        
        # Define bin edges based on bin_width
        data_min = samples.min()
        data_max = samples.max()
        bins = np.arange(data_min, data_max + bin_width, bin_width)
        
        # Compute histogram
        counts, bin_edges = np.histogram(samples, bins=bins)
        bin_centers = bin_edges[:-1] + bin_width / 2
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Plot the histogram
        ax.bar(bin_centers, counts, width=bin_width*0.9, color="steelblue", edgecolor="black", align='center')
        
        ax.set_title(f"Poisson Distribution Simulation (λ = {lam})", fontsize=16)
        ax.set_xlabel("Number of Events", fontsize=14)
        ax.set_ylabel("Frequency", fontsize=14)
        #ax.grid(True, axis='y', linestyle='--', alpha=0.7)
        
        # Set x-axis ticks to be at bin centers
        ax.set_xticks(bin_centers)
        
        # To avoid overcrowding, set a maximum number of x-ticks
        if len(bin_centers) > 20:
            step = math.ceil(len(bin_centers) / 20)
            ax.set_xticks(bin_centers[::step])
            ax.set_xticklabels([int(x) for x in bin_centers[::step]], rotation=90)
        else:
            ax.set_xticklabels([int(x) for x in bin_centers], rotation=90)
        
        plt.tight_layout()
        
        return fig

# Create the Shiny App
app = App(app_ui, server)
```

#### Summary

We keep this section brief as there are plenty of easily accessible references for discrete probability distributions. Hopefully the point was made though - that each discrete probability distribution is built on an idealized data generating process, and we can sample from the distribution as a way to model the outcomes of a process.

## Probability of Data

Having given some background on models, we can now focus on the probability of the data given the model, $P(D|M)$.

### Dice Totals Probability of Data

#### Relative Frequency

We want to find the probability of a particular dice total (the data) given a dice model. To estimate the probability $P(E)$ of an event $E$, we can use the relative frequency approach. This involves counting the number of occurrences of the event E and dividing it by the total number of trials. For example, if we observed a total of twelve occur in 40 out of 5,000 dice rolls, the probability estimate is:

$$
P(E) \approx \frac{\text{Number of times event } E \text{ occurs}}{\text{Total number of trials}} = \frac{40}{5000} = 0.008
$$

#### Law of Large Numbers 

The accuracy of this estimate depends on the total number of trials as governed by the Law of Large Numbers. The standard error, which gives a measure of uncertainty in the estimate of a mean value, is proportional to one over the square root of the number of samples:

$$
P_{\text{error}} \propto \frac{1}{\sqrt{N_{\text{total}}}}
$$

Which indicates there are diminishing returns to just making the sample size larger. Now I know you're smart, and you're saying to yourself, I can figure out the *exact* probability of rolling a certain dice total. Of course you can for this example - but you probably can't for more realistic examples, and we want to learn techniques that work well for real problems. In general, if you are concerned with the quality of an estimate with this approach, just rerun the model and see if the outcome changes meaningfully - if it does, increase the number of times we run the model until the output is stable enough for your application. If that's still not enough, dig into exact/analytic methods.

#### Revised Dice App

Here's another version of the Dice Total App that you saw earlier - except it now has additional functionality to calculate the approximate and exact probability of a certain dice total based on your inputs. It also shows the relative frequency of the dice sums, i.e. a true probability distribution where the sum of the probabilities equals one.

```{shinylive-python}
#| standalone: true
#| viewerHeight: 560

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt

# --- Utility function to compute exact distribution of sums for n dice ---
def dice_sum_distribution(n_dice):
    """
    Return a list 'dist' where dist[s] = probability of sum s for n_dice dice.
    Indices go from 0 up to 6*n_dice. Only sums in range [n_dice..6*n_dice]
    have nonzero probabilities.
    """
    # ways[s] = number of ways to get sum s
    ways = [0] * (6*n_dice + 1)
    ways[0] = 1  # base case

    for _ in range(n_dice):
        new_ways = [0] * (6*n_dice + 1)
        for sum_val, count in enumerate(ways):
            if count > 0:
                for face in range(1, 7):
                    new_ways[sum_val + face] += count
        ways = new_ways

    total_outcomes = 6 ** n_dice
    dist = [count / total_outcomes for count in ways]
    return dist

# -------------------------- UI Definition ---------------------------
app_ui = ui.page_fluid(
    ui.h2("Dice Rolling App with Probability Mass Function"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_slider("numDice", "Number of Dice", min=1, max=10, value=2, step=1),
            ui.input_slider("numRolls", "Number of Rolls", min=1, max=10000, value=100, step=1),
            ui.input_select(
                "selectedTotal", 
                "Select Dice Total", 
                choices=[""],   # initially empty, will be updated dynamically
                multiple=False,
            ),
            ui.output_text("approxProbability"),
            ui.output_text("exactProbability")
        ),
        ui.output_plot("dicePlot", height="400px"),
    )
)

# -------------------------- Server Definition -------------------------
def server(input, output, session):
    # Reactive: Generate random sums based on numDice and numRolls
    @reactive.Calc
    def dice_sums():
        return [
            np.random.randint(1, 7, input.numDice()).sum()
            for _ in range(input.numRolls())
        ]

    # Reactive: Exact distribution of sums for the current number of dice
    @reactive.Calc
    def exact_distribution():
        return dice_sum_distribution(input.numDice())

    # Dynamically update the choices in the 'selectedTotal' select input
    @reactive.Effect
    def _():
        current_sums = dice_sums()
        unique_sums = sorted(np.unique(current_sums))
        ui.update_select(
            "selectedTotal",
            choices=[str(s) for s in unique_sums],
            selected=str(unique_sums[0]) if len(unique_sums) > 0 else ""
        )

    # Plot the relative frequency of dice totals
    @output
    @render.plot
    def dicePlot():
        current_sums = dice_sums()
        
        fig, ax = plt.subplots()
        
        # Get theoretical distribution first to set x-axis limits
        dist = exact_distribution()
        theoretical_sums = range(input.numDice(), 6*input.numDice()+1)
        theoretical_probs = [dist[i] for i in theoretical_sums]
        
        # Create dictionary to store empirical probabilities for all possible sums
        empirical_dict = {i: 0 for i in theoretical_sums}
        unique_sums, counts = np.unique(current_sums, return_counts=True)
        for sum_val, count in zip(unique_sums, counts):
            if sum_val in empirical_dict:
                empirical_dict[sum_val] = count / len(current_sums)
        
        # Plot empirical distribution
        ax.bar([str(s) for s in theoretical_sums], 
               [empirical_dict[s] for s in theoretical_sums],
               color="steelblue", label="Empirical")
        
        # Plot theoretical distribution
        ax.plot([str(s) for s in theoretical_sums], theoretical_probs, 
                'r', marker='_', linestyle='', label="Theoretical")

        ax.set_title("Probability Mass Function of Dice Totals")
        ax.set_xlabel("Dice Total")
        ax.set_ylabel("Probability")
        ax.legend()
        plt.xticks(rotation=90)

        return fig

    # Approximate probability of the selected dice total
    @output
    @render.text
    def approxProbability():
        if not input.selectedTotal():
            return "Select a dice total to see probabilities."

        current_sums = dice_sums()
        selected_total = int(input.selectedTotal())

        count = sum(1 for x in current_sums if x == selected_total)
        if len(current_sums) == 0:
            prob = 0
        else:
            prob = count / len(current_sums)

        return f"Approx. Probability of {selected_total}: {prob:.4f}"

    # Exact probability of the selected dice total
    @output
    @render.text
    def exactProbability():
        if not input.selectedTotal():
            return ""

        selected_total = int(input.selectedTotal())
        dist = exact_distribution()

        # If the selected total is out of range, probability is 0
        if selected_total < 0 or selected_total >= len(dist):
            prob = 0
        else:
            prob = dist[selected_total]

        return f"Exact Probability of {selected_total}: {prob:.4f}"

app = App(app_ui, server)
```

Hopefully you can demonstrate to yourself that with enough samples, the approximate probability calculation is awfully close to the exact probability. However, there is an exception. The tails (the slim far ends) are not as accurate. Properly calculating probability in these tail sections happens to be trivial for dice where an exact solution is available, but for a real problem, accurate tail probabilities are incredibly difficult.

::: callout-note
A few readers may already know an essay called the 'The Bitter Lesson' by Rich Sutton. If you haven't read it, it is worth a read, and easily found on the internet. I believe it has a strong engineering corollary, in that our education is too obsessed with analytical solutions instead of computational ones. To temper that statement slightly, I can also assure you that solving problems through raw computation has its limits as there's no way to compute through a bad algorithm. But we're professionals in a hurry, we choose computation whenever it's plausible.
:::

### Exact Probabilities from a Discrete Probability Distribution

Here we provide an example of the more 'typical' use of a named discrete probability distribution, to compute the probability of an event. Let's use the properties of the binomial probability distribution to determine the probability of having less than 999 products pass a quality test when we have a true 0.999 pass rate and we inspect 1,000 products. 

We'll solve this problem by computing the probability of having 999 or 1,000 products pass, and then just inverting the probability. Note that $P(X = 1000)$ is simplified below based on the *multiplication rule of independent events* to equal 0.999\^1,000. Also, if you're unfamiliar with the n over k in parenthesis, look up 'n choose k'.

$$
P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}
$$

$$
P(X = 999) + P(X = 1,000) = \binom{1000}{999} (0.999)^{999} (0.001)^1 + (0.999)^{1,000}
$$

The result is 0.736, so the chance of having a real pass rate of 0.999 and having less than 999 pass is 1 - 0.736 = 0.264. It's fairly plausible to have 0.999 pass rate and have a couple of products fail. However, if you had four or more fail, you should have a very hard time convincing management that it was just 'bad luck'. The more formal way to discuss this is *hypothesis testing*.

::: callout-note
Much of statistics is dedicated to hypothesis testing. There's no reason for this primer to repeat such a repeated topic. The problem though, is that in the real world, folks get it wrong. I have a simple hypothesis for this, and that's because non-expert practitioners do not understand their statistical models. And there's good reasons they don't, they are often analytical mathematical 'magic' with buried assumptions. We take a different approach.
:::

### Probability of Multiple Events

So far we have only considered $P(D|M)$ where the data is a single event. However, it is more common to have multiple events (i.e. multiple data points), and we'd like to know the probability of a specific dataset vs other datasets we may have sampled. To calculate probabilities we'll use the *multiplication rule of independent events*. In practice it may be very difficult to prove perfectly independent events - however be sure there is not a reason for strong correlation, such as almost all *time series*.

#### Numerical Stability

We should also mention for many small probabilities, multiplication risks numerical instability. However there is one very simple and clever workaround to this, which is to add log probabilities instead:

$$
P(A \cap B \cap C \cap \dots) = P(A) \cdot P(B) \cdot P(C) \cdot \dots = 10^{(\log_{10}(P(A)) + \log_{10}(P(B)) + \log_{10}(P(C)) + \dots))}
$$

#### Example

Let's work through a couple example calculations before extending it to a scenario that approximates more serious problems we'll tackle later. What is the probability of rolling three dice out of a cup, where the total is 11, and then rolling the dice again, where the total is 7? We use the app above to get the probabilities of each roll, where 11 = 0.1250 and 7 = 0.0694.

$$
P(Roll 1 \cap Roll 2) = 0.1250 \cdot 0.0694 = 0.008675 = 10^{(\log_{10}(0.1250) + \log_{10}(0.0694))}
$$

If we stay in log probabilities, as that is generally more convenient:

$$
\log_{10}(P(Roll 1 \cap Roll 2)) = \log_{10}(0.1250) + \log_{10}(0.0694) = -0.9031 + -1.1586 = -2.0617
$$

### Calculating the Relative Probability of Multiple Events

With the background from the last section we can now simulate the probability of multiple events. However, often it is more useful to think about the relative probability of a long series of events rather than the absolute probability, since the absolute probability will be tiny. I think an example will help. Again, to have better intuition about the problem, we'll use dice, although it can obviously be extended to other discrete probability distributions.

We'll extend the recent example of rolling three dice out of a cup. We'll let most of our simulations use fair dice, and we'll show the log probability of each exact series of events as we perform rolls out of the cup. Note that for three dice, the values can range from 3 to 18, and values near the middle, such as 10, will be more common than those at the end, such as 3 or 18. The log probability of more rare events will be more negative. If we have a series of very unlikely events, the values will become negative more quickly.

We're also going to include one series of rolls with a cup of three weighted dice, which will be the dotted blue line. The values and probabilities will be 1=0.10, 2=0.10, 3=0.15, 4=0.15, 5=0.2, 6=0.3. If we expect the outcomes of fair dice, we'll see that the weighted dice will usually trend towards being a fairly improbable series of rolls. We can refer to the percentile of their log-probability to see how unusual they are.

```{shinylive-python}
#| standalone: true
#| viewerHeight: 650

from shiny import App, ui, render, reactive
import numpy as np
import matplotlib.pyplot as plt

# --- Utility Functions ---

def roll_three_dice_fair():
    """Simulate rolling three fair dice and return their sum."""
    return np.sum(np.random.randint(1, 7, size=3))

def roll_three_dice_weighted():
    """Simulate rolling three weighted dice and return their sum."""
    weights = [0.10, 0.10, 0.15, 0.15, 0.2, 0.30]
    # Define possible outcomes
    outcomes = [1, 2, 3, 4, 5, 6]
    # Roll three weighted dice
    return np.sum(np.random.choice(outcomes, size=3, p=weights))

def get_probability_of_sum(dice_sum):
    """Calculate probability of getting a specific sum with three fair dice."""
    possibilities = 0
    total_outcomes = 216  # 6^3 possible outcomes
    
    for i in range(1, 7):
        for j in range(1, 7):
            for k in range(1, 7):
                if i + j + k == dice_sum:
                    possibilities += 1
                        
    return possibilities / total_outcomes

def get_probability_of_sum_weighted(dice_sum):
    # We want to pretend it has the same probability and see how much of an outlier weighted dice are
    return get_probability_of_sum(dice_sum)

def simulate_rolls_fair(num_rolls=10):
    """Simulate a series of rolls with fair dice and calculate cumulative log probability."""
    rolls = [roll_three_dice_fair() for _ in range(num_rolls)]
    probabilities = [get_probability_of_sum(roll) for roll in rolls]
    
    # To handle log(0), replace zero probabilities with a very small number
    probabilities = [p if p > 0 else 1e-10 for p in probabilities]
    log_probs = np.log10(probabilities)
    cumulative_log_probs = np.cumsum(log_probs)
    
    return rolls, cumulative_log_probs

def simulate_rolls_weighted(num_rolls=10):
    """Simulate a series of rolls with weighted dice and calculate cumulative log probability."""
    rolls = [roll_three_dice_weighted() for _ in range(num_rolls)]
    probabilities = [get_probability_of_sum_weighted(roll) for roll in rolls]
    
    # To handle log(0), replace zero probabilities with a very small number
    probabilities = [p if p > 0 else 1e-10 for p in probabilities]
    log_probs = np.log10(probabilities)
    cumulative_log_probs = np.cumsum(log_probs)
    
    return rolls, cumulative_log_probs

# -------------------------- UI Definition ---------------------------
app_ui = ui.page_fluid(
    ui.h2("Three-Dice Roll Simulations with Cumulative Log Probability"),
    ui.layout_sidebar(
        ui.sidebar(
            ui.input_select(
                "selectedSim", 
                "Select Simulation to Highlight", 
                choices=[],   # initially empty, will be updated dynamically
                multiple=False,
            ),
            ui.output_text("selectedDetails"),
            ui.hr(),
            # Removed the Number of Simulations slider
            # Set Number of Simulations to 100 for fair and 5 for weighted
            # Retain Number of Rolls slider
            ui.input_slider("numRolls", "Number of Rolls per Simulation", min=5, max=100, value=10, step=1),
            ui.input_action_button("runSim", "Run Simulations")
        ),
        ui.output_plot("probPlot", height="500px"),
    )
)

# -------------------------- Server Definition -------------------------
def server(input, output, session):
    # Reactive value to store simulations as a list of tuples: (label, cum_log_probs)
    simulations = reactive.Value([])
    
    # Reactive: Perform simulations when 'Run Simulations' button is clicked
    @reactive.Effect
    def _run_simulations():
        input.runSim()  # Depend on the runSim button
        num_rolls = input.numRolls()
        new_simulations = []
        
        # Run 99 fair simulations (99 + 1 unfair = 100)
        num_sim_fair = 99
        for i in range(num_sim_fair):
            _, cum_probs = simulate_rolls_fair(num_rolls)
            label = f"Simulation {i+1}"
            new_simulations.append((label, cum_probs))
        
        # Run 1 weighted simulations (was 5)
        num_sim_weighted = 1
        for i in range(num_sim_weighted):
            _, cum_probs = simulate_rolls_weighted(num_rolls)
            label = f"Weighted Simulation {i+1}"
            new_simulations.append((label, cum_probs))
        
        simulations.set(new_simulations)
        
        # Update the select input choices
        sim_choices = [sim[0] for sim in new_simulations]
        ui.update_select(
            "selectedSim",
            choices=sim_choices,
            selected=sim_choices[0] if sim_choices else ""
        )
    
    # Initialize simulations on app start
    @reactive.Effect
    def _initialize():
        input.runSim()  # Trigger initial simulation run
    
    # Plot the simulations, highlighting the selected one
    @output
    @render.plot
    def probPlot():
        sims = simulations()
        num_sim = len(sims)
        if num_sim == 0:
            fig, ax = plt.subplots()
            ax.text(0.5, 0.5, "No simulations to display.\nClick 'Run Simulations' to start.", 
                    horizontalalignment='center', verticalalignment='center', fontsize=12)
            ax.axis('off')
            return fig
        
        num_rolls = len(sims[0][1])
        x = np.arange(1, num_rolls + 1)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Plot all fair simulations in light gray
        for label, probs in sims:
            if label.startswith("Simulation "):
                ax.plot(x, probs, color='#D3D3D3', alpha=0.5)
        
        # Plot all weighted simulations in blue
        for label, probs in sims:
            if label.startswith("Weighted Simulation "):
                ax.plot(x, probs, color='blue', alpha=0.7, linestyle='--')
        
        # Highlight the selected simulation
        selected = input.selectedSim()
        if selected:
            try:
                # Find the simulation by label
                selected_sim = next((sim for sim in sims if sim[0] == selected), None)
                if selected_sim:
                    label, selected_probs = selected_sim
                    color = 'red' if label.startswith("Simulation ") else 'green'
                    linestyle = '-' if label.startswith("Simulation ") else '--'
                    ax.plot(x, selected_probs, color=color, linewidth=2.5, linestyle=linestyle, label=label)
            except (IndexError, ValueError):
                pass
        
        ax.set_xlabel('Number of Rolls')
        ax.set_ylabel('Cumulative Log10 Probability')
        ax.set_title('Cumulative Log Probability of Multiple Three-Dice Roll Simulations')
        ax.grid(True)
        if selected:
            ax.legend()
        
        plt.tight_layout()
        return fig
    
    # Display details of the selected simulation, including percentile
    @output
    @render.text
    def selectedDetails():
        sims = simulations()
        selected = input.selectedSim()
        if not selected:
            return "No simulation selected."
        try:
            # Find the simulation by label
            selected_sim = next((sim for sim in sims if sim[0] == selected), None)
            if not selected_sim:
                return "Selected simulation not found."
            label, cum_probs = selected_sim
            # Get the final cumulative log probability
            final_log_prob = cum_probs[-1]
            # Collect all final cumulative log probabilities
            all_final_log_probs = [sim[1][-1] for sim in sims]
            # Compute percentile
            percentile = (np.sum(np.array(all_final_log_probs) <= final_log_prob) / len(all_final_log_probs)) * 100
            return (
                f"{label}\n\n"
                f"Final Cumulative Log10 Probability: {final_log_prob:.4f}\n"
                f"Percentile: {percentile:.2f}th"
            )
        except (IndexError, ValueError):
            return "Invalid selection."

app = App(app_ui, server)
```

You may notice that it's easier to spot the weighted dice with a longer series of rolls. In just a couple of rolls they often don't seem that unusual, but most of the time over 100 roles they have a markedly different slope than the other roles. When we calculate the percentile of the weighted dice, we are approximating the p-value of a hypothesis test. The p-value essentially says, if you assume your model is correct, here is the probability of witnessing data as, or more, extreme than what you witnessed. If the p-value becomes small enough, you may suspect it's not bad luck, but that the data is being generated by a different model.

::: callout-note
Traditional hypothesis testing starts with a *null* model which we can think of as the status quo. If the data has less than a (traditionally) 0.05 probability of being generated by that *null* model, we assume that something other than the *null* model generated the data.
:::