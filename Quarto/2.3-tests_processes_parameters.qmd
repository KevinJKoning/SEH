---
title: Wrap Up
format: html
filters:
  - shinylive
---



## Statistical Tests

Traditional statistical education is somewhat obsessed with testing if two data generating processes are different. (Our approach not only allows for determining if two data generating processes are different, but also making predictions about future data from the process). A common example of these 'significance tests' is a human's likelihood of dying while taking a medication vs not taking the medication. Obviously we prefer not to give people medications that are ineffective, so this is a reasonable question.

The typical approach goes something like this - if I assume I know the characteristics of data generating process A, and I know the data generated by a possibly different data generating process we'll call A/B - then how likely is the data, or even more extreme data/values, to come from A. If it is very unlikely to come from A, we'll conclude it is coming from another process, B.

That probably sounded somewhat confusing, and if you are confused, you are in good company. Many intelligent people publishing smart papers in reputable journals get significance testing not-quite-right, not to mention the arbitrary standard of rejecting a null hypothesis if p < 0.05, which should also be adjusted to the situation. Subsequently this text will spend no time on hypothesis testing, other than to say if it's important for you to determine if two data generating processes are different, I'm sure you can devise a method that makes sense and you can understand.

## Arbitrarily Complicated Processes

We are not limited to simple processes that create known probability distributions. We can combine any set of imaginable computational steps, including any probability distributions, together to form a more accurate estimate of the data generating process. A helpful visualization is a directed acyclic graph (DAG).

It is worth noting that a small number of parameters is generally called 'Statistics', modest to large number of parameters is called 'Machine Learning', and somewhere around a billion or more is called 'Artificial Intelligence'.

## Parameters

End with a discussion of parameters as they appear in probability distributions. Next we will move on to estimating these parameters in the second half of the book... (note that the second half will eventually need to cover MLE).